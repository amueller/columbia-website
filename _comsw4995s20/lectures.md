---
title: "COMS W4995 Applied Machine Learning Spring 2020 - Schedule"
layout: schedule
permalink: /comsw4995s20/schedule/
author_profile: false
sidebar:
  nav: "comsw4995s20"
---

Press P on slides for presenter notes (or add #p1 to the url if you're on mobile or click on <i class="fas fa-comment-dots"></i>).

<div class="schedule">
<table cellspacing="0" border="0">
	<colgroup span="2"></colgroup>
	<colgroup></colgroup>
	<colgroup></colgroup>
	<colgroup></colgroup>
    <tr>
        <th>#</th>
        <th style="width:126px">Date</th>
        <th style="width:330px">Topic</th>
        <th>Reading</th>
        <th style="width:115px">Comments</th>
    </tr>
	<tr>
		<td>1</td>
		<td>Wed 01/22/20</td>
		<td><a href="https://amueller.github.io/COMS4995-s20/slides/aml-01-introduction/">Introduction</a>
		<a href="https://amueller.github.io/COMS4995-s20/slides/aml-01-introduction/#p1"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="https://www.youtube.com/watch?v=rbvpiPJuK64&list=PL_pVmAaAnxIRnSw6wiCpSvshFyCREZmlM"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP Ch 1, APM Ch 1-2</td>
		<td><br></td>
	</tr>
	<tr>
		<td>2</td>
		<td>Mon 01/27/20</td>
		<td><a href="#">matplotlib and visualization</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td><a href="https://serialmentor.com/dataviz/">Fundamentals of Data Visualization</a>, <a href="https://ora.ox.ac.uk/objects/uuid:b98ccce1-038f-4c0a-a259-7f53dfe06ac7">Systematising Glyph Design for Visualization</a> (Chapter 2)</td>
		<td>HW 1 posted</td>
	</tr>
	<tr>
		<td>3<br></td>
		<td>Wed 01/29/20</td>
		<td>No class</td>
		<td></td>
		<td><br></td>
	</tr>
	<tr>
		<td>4</td>
		<td>Mon 02/03/20</td>
		<td><a href="#">Introduction to supervised learning</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>&nbsp;
		<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a>
        </td>
		<td>IMLP Ch2.1-2.3.2, APM Ch 4-4.3, IMLP Ch 5.1, 5.2, APM Ch 4.4-4.8</td>
		<td></td>
	</tr>
	<tr>
		<td>5<br></td>
		<td>Wed 02/05/20</td>
		<td><a href="#">Preprocessing</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a>
        </td>
		<td>IMLP Ch 3.3, IMLP Ch 4.1-4.6, APM Ch 3,</td>
		<td>HW 1 due, HW 2 posted</td>
	</tr>
	<tr>
		<td>6</td>
		<td>Mon 02/10/20</td>
		<td><a href="#">Linear models for Regression</a> <a href="#"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP p45-68, APM Ch 6</td>
		<td></td>
	</tr>
	<tr>
		<td>7</td>
		<td>Wed 02/12/20</td>
		<td><a href="#">Linear models for Classification, SVMs</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td></td>
		<td></td>
	</tr>
	<tr>
		<td>8</td>
		<td>Mon 02/17/20</td>
		<td><a href="#">Trees, Forests &amp; Ensembles</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP 2.3.5, 2.3.6, APM Ch 14.1-14.4</td>
		<td></td>
	</tr>
	<tr>
		<td>9<br></td>
		<td>Wed 02/19/20</td>
		<td><a href="#">Gradient Boosting, Calibration</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP 2.3.6, APM Ch 14.5</td>
		<td>HW 2 due</td>
	</tr>
	<tr>
		<td>10</td>
		<td>Mon 02/24/20</td>
		<td><a href="#">Model Evaluation</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP 5.3, APM Ch 16</td>
		<td>HW 3 posted</td>
	</tr>
	<tr>
		<td></td>
		<td>Wed 02/26/20</td>
		<td>No class
			</td>
		<td></td>
		<td></td>
	</tr>
	<tr>
		<td>11</td>
		<td>Mon 03/02/20</td>
		<td><a href="#">Learning with Imbalanced Data</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>APM Ch16, <a href="https://arxiv.org/pdf/1106.1813.pdf">SMOTE</a>, <a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tsmcb09.pdf">Easy Ensembles</a></td>
		<td></td>
	</tr>
	<tr>
		<td>12</td>
		<td>Wed 03/04/20</td>
        <td><a href="#">Model Interpretration and Feature Selection</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
        <td><a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning</a>, <a href="https://explained.ai/rf-importance/index.html">Beware Default Random Forest Importances</a></td>
		<td></td>
	</tr>
	<tr>
		<td>13</td>
		<td>Mon 03/09/20</td>
		<td><a href="#">Parameter tuning and Automatic Machine Learning</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		&nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td><a href="https://www.automl.org/book/">AutoML book (chapter 1 gives a great intro)</a>, <a href="https://www.youtube.com/watch?v=0eBR8a4MQ30">NeurIPS tutorial video</a></td>
		<td></td>
	</tr>
	<tr>
		<td><br></td>
		<td>Wed 03/11/20</td>
		<td><b>Midterm</b></td>
		<td><br></td>
		<td><br></td>
	</tr>
	<tr>
		<td></td>
		<td>Mon 03/16/20</td>
		<td><font color="#666666">Spring break</font></td>
		<td><br></td>
		<td><br></td>
	</tr>
	<tr>
		<td><br></td>
		<td>Wed 03/18/20</td>
		<td><font color="#666666">Spring break</font></td>
		<td><br></td>
		<td><br></td>
	</tr>
	<tr>
		<td>14</td>
		<td>Mon 03/23/20</td>
		<td><a href="#">Dimensionality Reduction</a>
		 <a href="#"><i class="fas fa-comment-dots"></i></a>
		 &nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP Ch 3.4.1, 3.4.3, APM p35-40</td>
        <td></td>
	</tr>
    <tr>
		<td>15</td>
		<td>Wed 03/25/20</td>
		<td><a href="#">Clustering and mixture models</a>
		 <a href="#"><i class="fas fa-comment-dots"></i></a>
		 &nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP 3.5</td>
		<td>HW 3 due</td>
	</tr>
	<tr>
		<td>16</td>
		<td>Mon 03/30/20</td>
		<td><a href="#">NMF and Outlier Detection</a>
		 <a href="#"><i class="fas fa-comment-dots"></i></a>
		 &nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP 3.4.2</td>
		<td></td>
	</tr>
	<tr>
		<td>17</td>
		<td>Wed 04/01/20</td>
		<td><a href="#">Working with text data</a>
		 <a href="#"><i class="fas fa-comment-dots"></i></a>
		 &nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP Ch 7.1-7.8</td>
		<td><br></td>
	</tr>
	<tr>
		<td>18</td>
		<td>Mon 04/06/20</td>
		<td><a href="#">Topic models for text data</a>
		 <a href="#"><i class="fas fa-comment-dots"></i></a>
		 &nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP Ch 7.9, <a href="https://www.youtube.com/watch?v=_R66X_udxZQ">Tim Hopper, Understanding Topic Models</a></td>
		<td>HW 4 posted</td>
	</tr>
	<tr>
		<td>19</td>
		<td>Wed 04/08/20</td>
		<td><a href="#">Word and document embeddings</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td><a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Mikolov 2013a</a>, <a href="http://www.aclweb.org/anthology/N13-1090">Mikolov 2013b</a>,
        <a href="https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/word2vec.ipynb">gensim word2vec</a></td>
		<td></td>
	</tr>
	<tr>
		<td>20</td>
		<td>Mon 04/13/20</td>
		<td><a href="#">Neural Networks</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td>IMLP Ch 2.3.8, <a href="http://www.deeplearningbook.org/contents/mlp.html">DL Ch 6</a>, <a href="http://www.deeplearningbook.org/contents/regularization.html">Ch 7.8</a></td>
		<td></td>
	</tr>
	<tr>
		<td>21</td>
		<td>Wed 04/15/20</td>
		<td><a href="#">Keras and Convolutional Neural Nets</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td><a href="http://www.deeplearningbook.org/contents/regularization.html">DL Ch 7.12</a>, <a href="http://www.deeplearningbook.org/contents/convnets.html">Ch 9</a>, <a href="https://keras.io/">keras docs</a>, <a href="http://cs231n.github.io/">Stanford CNN course notes, Module 2</a>, <a href="https://distill.pub/2017/feature-visualization/">Feature Visualization</a></td>
		<td>HW 4 due,  HW 5 posted</td>
	</tr>
	<tr>
		<td>22</td>
		<td>Mon 04/20/20</td>
		<td><a href="#">Advanced Neural Networks</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a>
		</td>
		<td></td>
		<td><br></td>
	</tr>
	<tr>
		<td>23</td>
		<td>Wed 04/22/20</td>
		<td><a href="#">Time series data</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		 &nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a>
		</td>
		<td></td>
		<td><br></td>
	</tr>
	<tr>
		<td>24</td>
		<td>Mon 04/27/20</td>
		<td><a href="#">Summary and Recap</a>
		<a href="#"><i class="fas fa-comment-dots"></i></a>
		 &nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a></td>
		<td><br></td>
		<td></td>
	</tr>
	<tr>
		<td>25</td>
		<td>Wed 04/29/20</td>
		<td><a href="#">Recommender systems taught by Nicolas Hug</a>
		 <a href="#"><i class="fas fa-comment-dots"></i></a>
		 &nbsp;<a href="#"><i class="fab fa-youtube" aria-hidden="true"></i></a>
		</td>
		<td><br></td>
		<td>HW 5 due</td>
	</tr>
	<tr>
		<td></td>
		<td>Mon 05/04/20</td>
		<td><b>Second Exam</b></td>
		<td><br></td>
		<td><br></td>
	</tr>
</table>
</div>

<div class="post">
<br>
<p>
IMLP: Mueller, Guido - Introduction to machine learning with python<br>
APM: Kuhn, Johnson - Applied predictive modeling<br>
DL: <a href="http://www.deeplearningbook.org/">Goodfellow, Bengio, Courville - Deep Learning</a>
</p>
</div>
